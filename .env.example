# ============================================================================
# LoRA Craft - Environment Configuration Template
# ============================================================================
# Copy this file to .env and customize the values for your environment
#
# Usage:
#   cp .env.example .env
#   # Edit .env with your preferred values
#   docker compose up -d
# ============================================================================

# ============================================================================
# FLASK CONFIGURATION
# ============================================================================

# Flask secret key for session management
# IMPORTANT: Change this to a random string in production!
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
FLASK_SECRET_KEY=dev-secret-key-change-in-production

# Flask application port (default: 5000)
PORT=5000

# Flask debug mode (set to 'false' in production)
FLASK_DEBUG=false

# ============================================================================
# GPU CONFIGURATION
# ============================================================================

# GPU device selection
# Examples:
#   CUDA_VISIBLE_DEVICES=0           # Use first GPU only
#   CUDA_VISIBLE_DEVICES=0,1         # Use first two GPUs
#   CUDA_VISIBLE_DEVICES=all         # Use all available GPUs
CUDA_VISIBLE_DEVICES=0

# ============================================================================
# HUGGINGFACE CONFIGURATION
# ============================================================================

# HuggingFace authentication token (optional, for private models/datasets)
# Get yours at: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_your_token_here

# HuggingFace cache directory (default: /app/cache/huggingface)
HF_HOME=/app/cache/huggingface

# Transformers cache (default: /app/cache/transformers)
TRANSFORMERS_CACHE=/app/cache/transformers

# Datasets cache (default: /app/cache/datasets)
HF_DATASETS_CACHE=/app/cache/datasets

# Enable HuggingFace transfer acceleration (optional)
# HF_HUB_ENABLE_HF_TRANSFER=1

# ============================================================================
# PYTORCH CONFIGURATION
# ============================================================================

# PyTorch cache directory
TORCH_HOME=/app/cache/torch

# PyTorch CUDA memory allocation settings (optional)
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================

# Maximum number of workers for data loading (default: 4)
# Adjust based on CPU cores available
# NUM_WORKERS=4

# Mixed precision training (default: true for faster training)
# USE_MIXED_PRECISION=true

# Gradient checkpointing (default: false, enable to save memory)
# USE_GRADIENT_CHECKPOINTING=false

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log directory (default: /app/logs)
LOG_DIR=/app/logs

# ============================================================================
# SECURITY CONFIGURATION
# ============================================================================

# Maximum file upload size in GB (default: 10)
MAX_UPLOAD_SIZE_GB=10

# Allowed CORS origins (default: * for development)
# In production, set to specific domains:
# CORS_ORIGINS=https://yourdomain.com,https://app.yourdomain.com
CORS_ORIGINS=*

# ============================================================================
# ADVANCED CONFIGURATION
# ============================================================================

# Custom model download directory (optional)
# MODEL_CACHE_DIR=/app/cache/models

# Custom dataset download directory (optional)
# DATASET_CACHE_DIR=/app/cache/datasets

# Custom export directory (optional)
# EXPORT_DIR=/app/exports

# Custom output directory (optional)
# OUTPUT_DIR=/app/outputs

# ============================================================================
# NVIDIA DOCKER CONFIGURATION
# ============================================================================

# These are set automatically by docker-compose.yml, but can be overridden
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility

# ============================================================================
# NOTES
# ============================================================================
#
# 1. DO NOT commit .env to version control (it's in .gitignore)
# 2. Always use strong, random values for FLASK_SECRET_KEY in production
# 3. GPU memory requirements vary by model size:
#    - 0.6B-1.7B models: 4-8GB VRAM
#    - 3B-4B models: 8-12GB VRAM
#    - 7B-8B models: 16GB+ VRAM
# 4. Adjust CUDA_VISIBLE_DEVICES if you have multiple GPUs
# 5. For private HuggingFace models, you must set HF_TOKEN
#
# ============================================================================
